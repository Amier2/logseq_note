## 背景
- **重复编码**：现有 Text-to-SQL 系统每次提问都要把整张 schema（表名、列名、外键、采样值等）再喂一遍，token 爆炸，推理慢。
- **信息缺失**：线性化 schema 常常漏掉关键单元格值、缩写、领域知识。
- **检索负担**：为了补全值，还要额外做 cell-value retrieval，容易因缩写或别名检索失败而整体翻车。
- ## 方法
- ### 阶段 1：知识内化（训练期）
- 对每张目标库自动生成大量 synthetic NLQ-SQL 对（骨架-填充-回译三步法）。
- 用这些数据对开源大模型（LLaMA-7B/13B、Mistral-7B）做 continue-training，把 schema、值、关系全部压进权重。
- 每个数据库训练一个“领域专家”小模型，避免跨库混淆。
- ### 阶段 2：推理期
- prompt 只保留一个数据库 ID + 自然语言问题，**零 schema、零采样值**。
- 模型直接吐出 SQL，无需再查库。