public:: true

- ## ACL Findings 2025
-
- ## 背景
- 传统的任务规划方法通常采用**正向推理**，即从智能体的初始状态出发，一步步推断下一步该做什么，直到达成目标。
- 作者认为任务的初始状态与最终目标之间存在着巨大的“感知鸿沟”
- ## 方法
- 从最终目标状态倒推，思考达成这个目标的前置条件是什么，然后将这些前置条件作为新的子目标，继续倒推，直到找到一条从初始状态到目标状态的完整路径。
- ![BAR](https://github.com/WitcherLeo/BAR/raw/main/imgs/bar.png)
- ### Recursive Goal Decomposition
	- 动态规划，递归地将每个目标分解成一个可以“一步达成”的执行步骤，以及一组必须在该步骤执行前完成的子目标。维护一个步骤栈和目标队列
- ### State Consistency Maintenance
	- 引入正向推理作为补充。它在由反向推理生成的初始计划中选取关键节点，然后在每对关键节点之间使用正向推理来验证和修正状态转换的合理性，从而确保整个计划是可执行的。
- ### Stage Memory
	- 将多次迭代分解任务目标时的分解结果记录及执行成功率记录下来，形成阶段记忆。在新任务规划中，可检索高成功率的相同目标分解结果，辅助新任务目标分解，从而持续提升分解效率。