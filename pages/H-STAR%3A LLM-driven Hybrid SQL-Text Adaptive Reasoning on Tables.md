## 背景
- **纯文本推理**：擅长语义、指代消解，但一遇到「求平均、过滤、跨列计算」就翻车。
- **纯 SQL / 符号推理**：数学精确，却常被一词多义、口语化表达卡住。
  → 需要“什么时候算、什么时候读”的自适应机制。
- ## 方法
- ### Multi-View 表裁剪
	- #### 列检索
		- ‑ 把原表和其“转置表”一起喂 LLM，做 few-shot prompt 选列；
		  ‑ 兼顾列名语义与单元格值匹配，过滤掉 70-90 % 无关列。
	- #### 行检索
		- ‑ 在已裁剪列上再用 LLM 筛行，得到“最小可回答子表” **T_CR**。
	- #### 设计思路
		- • 只按**列名**检索：容易遗漏“值里才出现的同义词”
		- • 只按**单元格值**检索：列名语义丢失，常把无关列召回
		- Multi-View 把“横向的列名+纵向的值”同时喂给 LLM，让两种信号互相印证，召回-噪声比提升 30 % 以上
		- • 当表有 50 列以上，prompt 会爆炸；转置后列变行、行变列，一次裁剪就能砍掉 70-90 % 的 token
		- • 转置后的“行”其实正是原表的列名，LLM 仍能看到它们，语义不会丢失
		- • 单一视图下，LLM 可能把“看似无关”的列直接删掉，导致后续无法回答
		- • 两个视图交叉验证后，真正无关的列才会被一致地剔除，从而显著降低幻觉
- ### Adaptive 推理
- LLM 先用 2-shot CoT 判断问题类型：
  – 直接查找 / 常识 / 复杂词汇 → 仅用语义推理在 **T_CR** 上回答；
  – 数值、逻辑、聚合 → 额外生成一条 SQL 在 T_CR 上执行，把结果作为补充证据再回答。
- 整个流程无需训练，完全靠 prompt + 执行器完成。